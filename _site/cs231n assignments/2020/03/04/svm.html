<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="https://gmpg.org/xfn/11" rel="profile" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1" />

  <title>
    
      Implement and Apply a Multiclass Support Vector Machine (SVM) Classifier -- CS231n Exercise &middot; UR Machine Learning Blog
    
  </title>

  


  <!-- CSS -->
  <link rel="stylesheet" href="/urmlblog/assets/css/main.css" />
  

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface" />

  <!-- Icons -->
<!--  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/urmlblog/favicon.png" />
<link rel="shortcut icon" href="/urmlblog/favicon.ico" />-->

  <!-- RSS -->
<!--  <link rel="alternate" type="application/rss+xml" title="RSS" href="/urmlblog/feed.xml" />-->

  <!-- Additional head bits without overriding original head -->
</head>


  <script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: { equationNumbers: { autoNumber: "all" } }
  });
  MathJax.Hub.Config({ TeX: { extensions: ["color.js"] }});
<!--  MathJax.Hub.Config({-->
<!--    jax: ["input/TeX","output/HTML-CSS"],-->
<!--    displayAlign: "left"-->
<!--  });-->
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/urmlblog/favicon.png" />
<link rel="shortcut icon" href="/urmlblog/favicon.ico" />

  <body class="post">

    <div id="sidebar">
  <header>
    <div class="site-title">
      <a href="/urmlblog/">
        
          <span class="back-arrow icon"><svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
  <path d="M0 0h24v24H0z" fill="none"/>
  <path d="M20 11H7.83l5.59-5.59L12 4l-8 8 8 8 1.41-1.41L7.83 13H20v-2z"/>
</svg></span>
        
        UR Machine Learning Blog
      </a>
    </div>
    <p class="lead">Data Scientist at City of Edmonton</p>
  </header>
  <nav id="sidebar-nav-links">
  
    <a class="home-link "
        href="/urmlblog/">Home</a>
  
  

  

  


  
    
  

  
    
      <a class="page-link "
          href="/urmlblog/about.html">About</a>
    
  

  
    
  

  
    
  

  

  
    
  

  
    
  

  

  

  

  

  
    
  

  
    
  

  
    
  


  


  
    
  

  
    
  

  
    
      <a class="category-link "
          href="/urmlblog/category/categories.html">Categories</a>
    
  

  
    
  

  

  
    
  

  
    
  

  

  

  

  

  
    
  

  
    
  

  
    
  


  <!-- Optional additional links to insert in sidebar nav -->
</nav>


  

  <nav id="sidebar-icon-links">
  

<!--  <a id="subscribe-link"-->
<!--     class="icon" title="Subscribe" aria-label="Subscribe"-->
<!--     href="/urmlblog/feed.xml">-->
<!--    <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <circle cx="6.18" cy="17.82" r="2.18"/>
    <path d="M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z"/>
</svg>-->
<!--  </a>-->

  
  
  
  

  <a id="linkedin-link"
       title="Linkedin" aria-label="linkedin" class="icon" target="_blank"
       href="https://www.linkedin.com/in/usman-rizwan-data-magic/">
      <?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="24pt" height="24pt" viewBox="0 0 24 24" version="1.1">
<defs>
<filter id="alpha" filterUnits="objectBoundingBox" x="0%" y="0%" width="100%" height="100%">
  <feColorMatrix type="matrix" in="SourceGraphic" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0"/>
</filter>
<mask id="mask0">
  <g filter="url(#alpha)">
<rect x="0" y="0" width="24" height="24" style="fill:rgb(0%,0%,0%);fill-opacity:0.780392;stroke:none;"/>
  </g>
</mask>
<linearGradient id="linear0" gradientUnits="userSpaceOnUse" x1="-808.8727" y1="199.8918" x2="-860.5692" y2="49.2029" gradientTransform="matrix(-0.0554531,0,0,-0.0554531,-38.267222,8.831372)">
<stop offset="0" style="stop-color:rgb(100%,100%,100%);stop-opacity:1;"/>
<stop offset="1" style="stop-color:rgb(100%,100%,100%);stop-opacity:0;"/>
</linearGradient>
<clipPath id="clip1">
  <rect width="24" height="24"/>
</clipPath>
<g id="surface6" clip-path="url(#clip1)">
<path style=" stroke:none;fill-rule:nonzero;fill:url(#linear0);" d="M 17.195312 1.925781 L 6.804688 1.925781 C 4.054688 1.925781 1.839844 4.160156 1.839844 6.929688 L 1.839844 17.070312 C 1.929688 19.234375 2.273438 17.863281 2.921875 15.46875 C 3.679688 12.683594 6.148438 10.246094 9.152344 8.421875 C 11.445312 7.03125 14.011719 6.140625 18.683594 6.054688 C 21.335938 6.007812 21.101562 2.617188 17.195312 1.925781 Z M 17.195312 1.925781 "/>
</g>
</defs>
<g id="surface1">
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(11.372549%,54.901961%,70.980392%);fill-opacity:1;" d="M 19.6875 0.984375 L 4.3125 0.984375 C 2.472656 0.984375 0.984375 2.472656 0.984375 4.3125 L 0.984375 19.6875 C 0.984375 21.527344 2.472656 23.015625 4.3125 23.015625 L 19.6875 23.015625 C 21.527344 23.015625 23.015625 21.527344 23.015625 19.6875 L 23.015625 4.3125 C 23.015625 2.472656 21.527344 0.984375 19.6875 0.984375 Z M 19.6875 0.984375 "/>
<use xlink:href="#surface6" mask="url(#mask0)"/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;" d="M 7.648438 19.476562 L 7.648438 9.515625 L 4.339844 9.515625 L 4.339844 19.476562 Z M 5.996094 8.15625 C 7.148438 8.15625 7.867188 7.390625 7.867188 6.433594 C 7.847656 5.457031 7.148438 4.710938 6.015625 4.710938 C 4.882812 4.710938 4.144531 5.457031 4.144531 6.433594 C 4.144531 7.390625 4.863281 8.15625 5.972656 8.15625 Z M 5.996094 8.15625 "/>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(100%,100%,100%);fill-opacity:1;" d="M 9.484375 19.476562 L 12.792969 19.476562 L 12.792969 13.914062 C 12.792969 13.617188 12.816406 13.320312 12.902344 13.105469 C 13.144531 12.511719 13.6875 11.894531 14.601562 11.894531 C 15.800781 11.894531 16.28125 12.808594 16.28125 14.148438 L 16.28125 19.476562 L 19.589844 19.476562 L 19.589844 13.765625 C 19.589844 10.703125 17.957031 9.28125 15.777344 9.28125 C 13.992188 9.28125 13.207031 10.277344 12.773438 10.960938 L 12.792969 10.960938 L 12.792969 9.515625 L 9.484375 9.515625 C 9.527344 10.449219 9.484375 19.476562 9.484375 19.476562 Z M 9.484375 19.476562 "/>
</g>
</svg>

    </a>

    <a id="github-link"
       title="Github" aria-label="github" class="icon" target="_blank"
       href="https://github.com/usmanr149/">
      <svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 28" height="24" width="28"><path d="M12 2c6.625 0 12 5.375 12 12 0 5.297-3.437 9.797-8.203 11.391-0.609 0.109-0.828-0.266-0.828-0.578 0-0.391 0.016-1.687 0.016-3.297 0-1.125-0.375-1.844-0.812-2.219 2.672-0.297 5.484-1.313 5.484-5.922 0-1.313-0.469-2.375-1.234-3.219 0.125-0.313 0.531-1.531-0.125-3.187-1-0.313-3.297 1.234-3.297 1.234-0.953-0.266-1.984-0.406-3-0.406s-2.047 0.141-3 0.406c0 0-2.297-1.547-3.297-1.234-0.656 1.656-0.25 2.875-0.125 3.187-0.766 0.844-1.234 1.906-1.234 3.219 0 4.594 2.797 5.625 5.469 5.922-0.344 0.313-0.656 0.844-0.766 1.609-0.688 0.313-2.438 0.844-3.484-1-0.656-1.141-1.844-1.234-1.844-1.234-1.172-0.016-0.078 0.734-0.078 0.734 0.781 0.359 1.328 1.75 1.328 1.75 0.703 2.141 4.047 1.422 4.047 1.422 0 1 0.016 1.937 0.016 2.234 0 0.313-0.219 0.688-0.828 0.578-4.766-1.594-8.203-6.094-8.203-11.391 0-6.625 5.375-12 12-12zM4.547 19.234c0.031-0.063-0.016-0.141-0.109-0.187-0.094-0.031-0.172-0.016-0.203 0.031-0.031 0.063 0.016 0.141 0.109 0.187 0.078 0.047 0.172 0.031 0.203-0.031zM5.031 19.766c0.063-0.047 0.047-0.156-0.031-0.25-0.078-0.078-0.187-0.109-0.25-0.047-0.063 0.047-0.047 0.156 0.031 0.25 0.078 0.078 0.187 0.109 0.25 0.047zM5.5 20.469c0.078-0.063 0.078-0.187 0-0.297-0.063-0.109-0.187-0.156-0.266-0.094-0.078 0.047-0.078 0.172 0 0.281s0.203 0.156 0.266 0.109zM6.156 21.125c0.063-0.063 0.031-0.203-0.063-0.297-0.109-0.109-0.25-0.125-0.313-0.047-0.078 0.063-0.047 0.203 0.063 0.297 0.109 0.109 0.25 0.125 0.313 0.047zM7.047 21.516c0.031-0.094-0.063-0.203-0.203-0.25-0.125-0.031-0.266 0.016-0.297 0.109s0.063 0.203 0.203 0.234c0.125 0.047 0.266 0 0.297-0.094zM8.031 21.594c0-0.109-0.125-0.187-0.266-0.172-0.141 0-0.25 0.078-0.25 0.172 0 0.109 0.109 0.187 0.266 0.172 0.141 0 0.25-0.078 0.25-0.172zM8.937 21.438c-0.016-0.094-0.141-0.156-0.281-0.141-0.141 0.031-0.234 0.125-0.219 0.234 0.016 0.094 0.141 0.156 0.281 0.125s0.234-0.125 0.219-0.219z"></path>
</svg>

    </a>

  
    <a id="tags-link"
       class="icon"
       title="Tags" aria-label="Tags"
       href="/urmlblog/tags.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
    </a>
  

  
    <a id="search-link"
       class="icon"
       title="Search" aria-label="Search"
       href="/urmlblog/search.html">
      <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"/>
    <path d="M0 0h24v24H0z" fill="none"/>
</svg>
    </a>
  

  <!-- Optional additional links to insert for icons links -->
</nav>

  <!--<p>-->
<!--  &copy; 2022.-->
<!--  <a href="/urmlblog/LICENSE.md">MIT License.</a>-->
<!--</p>-->

</div>

    <main class="container">
      <header>
  <h1 class="post-title">Implement and Apply a Multiclass Support Vector Machine (SVM) Classifier -- CS231n Exercise</h1>
</header>
<div class="content">
  <div class="post-meta">
  <span class="post-date">04 Mar 2020</span>
  <span class="post-categories">
    
      &bull;

      
      
      

      
        CS231n assignments
      
    
  </span>
</div>


  <div class="post-body">
    <p class="message">
I am currently working my way through the lectures for 
<a href="https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;index=1">CS231n: Convolutional Neural Networks for Visual Recognition</a>.
I will post my solutions <a href="https://usmanr149.github.io/urmlblog/">here</a>.
</p>

<p>In this exercise we are asked to train a loss function using the SVM classifier 
on the CIFAR-10 dataset.</p>

<h3 id="linear-classifier-for-images">Linear Classifier for Images</h3>

<p>According to <a href="http://cs231n.github.io/linear-classify/">lecture notes</a>, we define the 
score function as</p>

\[\begin{align*}
  f(X_i,W) = WX_i
\end{align*}\]

<p>In the CIFAR-10 example, \(X_i\) is 3x32x32+1 - with the additional dimension holding the constant 1.</p>

<p>In an expanded format this is what the matrix multiplication will look like:</p>

\[\begin{align*}
  \begin{pmatrix}
W_{0,0} &amp; W_{0,1} &amp; \dots &amp; W_{0,3073} \\
W_{1,0} &amp; W_{1,1} &amp; \dots &amp; W_{1,3073} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
W_{9,0} &amp; W_{9,1} &amp; \dots &amp; W_{9,3073} \\
\end{pmatrix}
\begin{pmatrix}
X_{0,i} \\
X_{1,i} \\
\vdots \\
X_{3072,i} \\
1
\end{pmatrix}
=
\begin{pmatrix}
f(i,0) \\
f(i,1) \\
\vdots \\
f(i,9)
\end{pmatrix}
\end{align*}\]

<p>where \(f(i,0)\) is the score for image \(i\) belonging to class 0, \(f(i,1)\) is the 
score for image \(i\) belonging to class 1, and so on.</p>

<p>Lets take a closer at an element of the weight matrix, \(W_{k,l}\). Here \(k\) 
is the class and the \(l\) is the pixel. \(W_{k,l}\) is the
weight that the pixel \(l\) contributes to an image score for
class \(k\). A high \(W_{k,l}\) means that the pixel \(l\) of images in our training set is 
highly correlated to it belonging to class \(k\).</p>

<h3 id="multiclass-svm-loss-function">Multiclass SVM Loss Function</h3>

<p>The SVM loss function is setup so that the score for \(f(i,y_i)\) is highest 
when \(y_i\) is the true class for image \(i\). More precisely, the 
multiclass SVM loss for for \(i\)-th example is</p>

\[\begin{align*}
L_i = \sum_{j \neq y_i} \text{max}(0, f(i,j) - f(i,y_i) + \Delta)
\end{align*}\]

<p>Here is a naive way to calculate the loss for all images in the training set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># compute the loss
</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_train</span><span class="p">):</span>
    <span class="c1"># i is the image under consideration
</span>    <span class="n">scores</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">correct_class_score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="c1"># j is the class
</span>        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="n">margin</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">correct_class_score</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># note delta = 1
</span>        <span class="k">if</span> <span class="n">margin</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">margin</span>
</code></pre></div></div>

<h4 id="how-to-calculate-the-gradient-for-the-loss">How to calculate the gradient for the loss</h4>

<p>The full Multiclass SVM loss is given by</p>

\[\begin{align*}
L = \frac{1}{N}\sum_i L_i + \lambda*||W||^2
\end{align*}\]

<p>Where \(N\) is the number of images in the training set, \(\begin{align*}
\lambda
\end{align*}\) is the weighing hyperparameters, \(||W||^2\) is the square of the L2-norm of 
the weight matrix \(W\).</p>

<p>To start with, lets take the derivative of \(L\) with respect to an arbitrary element from the
 weight matrix, \(W_{k,l}\).</p>

\[\begin{align}
\frac{\partial L}{\partial W_{k,l}} &amp;= \frac{\partial (\frac{1}{N}\sum_i L_i 
+ \lambda*||W||^2)}{\partial W_{k,l}} \\
&amp;= \frac{1}{N}\frac{\partial \sum_i L_i}{\partial W_{k,l}} + 2*\lambda*W_{k,l}
\end{align}\]

<p>Focusing on \(\begin{align*}\sum_i L_i
\end{align*}\).</p>

\[\begin{align}
\sum_i L_i &amp;= \sum_{i} \sum_{j \neq y_i} \text{max}(0, f(i,j) - f(i,y_i) + \Delta) \\
&amp;= \sum_{i} \sum_{j \neq y_i} \text{max}(0, \sum_h W_{j,h}X_{h,i} - \sum_h W_{y_i,h}X_{h,i}
 + \Delta)
\end{align}\]

\[\begin{align}
\frac{\partial \sum_i L_i}{\partial W_{k,l}} &amp;=
\frac{\partial \sum_{i} \sum_{j \neq y_i} \text{max}(0, \sum_h W_{j,h}X_{h,i} - \sum_h W_{y_i,h}X_{h,i}
 + \Delta)}{\partial W_{k,l}} \\
 &amp;= \sum_{i, \text{where } y_i \neq k}\begin{cases}
    X_{l,i}, &amp; \text{if } \sum_h W_{j,h}X_{h,i} - \sum_h W_{y_i,h}X_{h,i} + \Delta &gt; 0\\
    0,              &amp; \text{otherwise}
    \end{cases} \\
&amp;+ \sum_{i, \text{where } y_i = k} \sum_{j \neq y_i} \begin{cases}
    -X_{l,i}, &amp; \text{if } \sum_h W_{j,h}X_{h,i} - \sum_h W_{y_i,h}X_{h,i} + \Delta &gt; 0\\
    0,              &amp; \text{otherwise}
    \end{cases}
\end{align}\]

<p>Use the equations above to calculate the gradient and the loss within the 
same loops:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">W</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># initialize the gradient as zero
</span>
<span class="c1"># compute the loss
</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">W</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_train</span><span class="p">):</span>
    <span class="c1"># i is the image under consideration
</span>    <span class="n">scores</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
    <span class="n">correct_class_score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_classes</span><span class="p">):</span>
        <span class="c1"># j is the class
</span>        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="k">continue</span>
        <span class="n">margin</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">-</span> <span class="n">correct_class_score</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># note delta = 1
</span>        <span class="k">if</span> <span class="n">margin</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">margin</span>
            <span class="n">dW</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dW</span><span class="p">[:,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">dW</span><span class="p">[:,</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">dW</span><span class="p">[:,</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
</code></pre></div></div>

<p>Taking regularization parameters into account:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Right now the loss is a sum over all training examples, but we want it
# to be an average instead so we divide by num_train.
</span><span class="n">loss</span> <span class="o">/=</span> <span class="n">num_train</span>
<span class="n">dW</span> <span class="o">/=</span> <span class="n">num_train</span>

<span class="c1"># Add regularization to the loss.
</span><span class="n">loss</span> <span class="o">+=</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">W</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span>
<span class="n">dW</span> <span class="o">+=</span> <span class="mi">2</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">W</span>
</code></pre></div></div>

<h3 id="vectorizing-svm-loss-and-gradient">Vectorizing SVM Loss and Gradient</h3>

<p>Vectorizing the loss function is actually straight forward.</p>

\[\begin{align}
WX &amp;= \begin{pmatrix}
W_{0,0} &amp; W_{0,1} &amp; \dots &amp; W_{0,3073} \\
W_{1,0} &amp; W_{1,1} &amp; \dots &amp; W_{1,3073} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
W_{9,0} &amp; W_{9,1} &amp; \dots &amp; W_{9,3073} \\
\end{pmatrix}\begin{pmatrix}
X_{0,0} &amp; X_{0,1} &amp; \dots &amp; X_{0,50000}\\
X_{1,0} &amp; X_{1,1} &amp; \dots &amp; X_{1,50000} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
X_{3072,0} &amp; X_{3072,1} &amp; \dots &amp; X_{3072,50000} \\
1 &amp; 1 &amp; \dots &amp; 1
\end{pmatrix} \\
&amp;= \begin{pmatrix}
f(0,0) &amp; f(1,0) &amp; \dots &amp; f(50000,0) \ \\
f(0,1) &amp; f(2,1) &amp; \dots &amp; f(50000,1) \\
\vdots &amp; \vdots &amp; \ddots &amp;  \vdots \\
f{0,9} &amp; f(2,9) &amp; \dots &amp; f(50000,9)
\end{pmatrix}
\end{align}\]

<p>All we need to do is subtract \(f(i,y_i)\) from each column and set 
\((i,y_i)\) to 0. Here is the python version:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ytrue_class_prob</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="n">i</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">)])</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
<span class="n">P</span> <span class="o">=</span> <span class="n">P</span> <span class="o">-</span> <span class="n">P</span><span class="p">[</span><span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]].</span><span class="n">reshape</span><span class="p">(</span><span class="n">P</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">myfunc</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">m</span>
    <span class="k">return</span> <span class="mf">0.</span>

<span class="n">vfunc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">myfunc</span><span class="p">)</span>

<span class="n">P_</span> <span class="o">=</span> <span class="n">vfunc</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="n">P_</span><span class="p">[</span><span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">loss</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">P_</span><span class="p">))</span>
<span class="n">loss</span> <span class="o">/=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">+=</span> <span class="n">reg</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">W</span> <span class="o">*</span> <span class="n">W</span><span class="p">)</span>
</code></pre></div></div>

<p>Now to vectorize the gradient</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">myfuncder</span><span class="p">(</span><span class="n">m_</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">m_</span> <span class="o">&gt;</span> <span class="mf">0.</span> <span class="p">:</span>
        <span class="k">return</span> <span class="mf">1.</span>
    <span class="k">return</span> <span class="mf">0.</span>

<span class="n">vfunc_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">myfuncder</span><span class="p">)</span>

<span class="n">P_der</span> <span class="o">=</span> <span class="n">vfunc_</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="c1"># count the number of examples where margin &gt; 0
</span><span class="n">P_der</span><span class="p">[</span><span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nansum</span><span class="p">(</span><span class="n">P_der</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">P_der</span><span class="p">[</span><span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">ytrue_class_prob</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="o">-</span><span class="n">count</span>

<span class="n">dW</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">P_der</span><span class="p">)</span><span class="o">/</span><span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">reg</span><span class="o">*</span><span class="n">W</span>
</code></pre></div></div>

<p>Check out the full assignment <a href="https://github.com/usmanr149/CS231n/blob/master/assignment1/svm.ipynb" target="_blank">here</a></p>

    



<div class="post-tags">
  
    
    <a href="/urmlblog/tags.html#svm">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">SVM</span>
    </a>
  
    
    <a href="/urmlblog/tags.html#cs231n">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">CS231n</span>
    </a>
  
    
    <a href="/urmlblog/tags.html#cifar-10">
    
      <span class="icon">
        <svg fill="#000000" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg">
    <path d="M0 0h24v24H0z" fill="none"/>
    <path d="M17.63 5.84C17.27 5.33 16.67 5 16 5L5 5.01C3.9 5.01 3 5.9 3 7v10c0 1.1.9 1.99 2 1.99L16 19c.67 0 1.27-.33 1.63-.84L22 12l-4.37-6.16z"/>
</svg>
      </span>&nbsp;<span class="tag-name">cifar-10</span>
    </a>
  
</div>
  </div>

  
  <section class="comments">
    <h2>Comments</h2>
    
  <div id="disqus_thread">
    <button class="disqus-load" onClick="loadDisqusComments()">
      Load Comments
    </button>
  </div>
  <script>

  /**
  *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW
  *  TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
  *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT:s
  *  https://disqus.com/admin/universalcode/#configuration-variables
  */
  var disqus_config = function () {
    this.page.url = "http://localhost:4000/urmlblog/cs231n%20assignments/2020/03/04/svm.html";
    this.page.identifier = "" ||
                           "http://localhost:4000/urmlblog/cs231n%20assignments/2020/03/04/svm.html";
  }
  function loadDisqusComments() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = '//https-usmanr149-github-io-urmlblog.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  }
  </script>
  <noscript>
    Please enable JavaScript to view the
    <a href="https://disqus.com/?ref_noscript">comments powered by Disqus</a>.
  </noscript>



  </section>

  <section class="related">
  <h2>Related Posts</h2>
  <ul class="posts-list">
    
      <li>
        <h3>
          <a href="/urmlblog/geometry/2022/10/14/Point-in-Rectangle.html">
            Point in Rectangle
            <small>14 Oct 2022</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/urmlblog/computer%20vision/2022/09/10/Implenting-SSD-TF2.html">
            Implementing a Single Shot Detector Model in Tensorflow 2.0
            <small>10 Sep 2022</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/urmlblog/computer%20vision/2022/09/09/SSD-Anchorboxes.html">
            Generating Anchor Boxes
            <small>09 Sep 2022</small>
          </a>
        </h3>
      </li>
    
  </ul>
</section>

</div>

    </main>

    <!-- Optional footer content -->

  </body>
</html>
